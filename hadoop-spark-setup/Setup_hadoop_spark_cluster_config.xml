<?xml version='1.0' encoding='UTF-8'?>
<project>
  <actions/>
  <description></description>
  <keepDependencies>false</keepDependencies>
  <properties>
    <hudson.model.ParametersDefinitionProperty>
      <parameterDefinitions>
        <hudson.model.TextParameterDefinition>
          <name>USER</name>
          <description>Linux user under whose home directory you want to setup TPCDS on master machine</description>
          <defaultValue>hdp_test</defaultValue>
        </hudson.model.TextParameterDefinition>
        <hudson.model.TextParameterDefinition>
          <name>MASTER_HOSTNAME</name>
          <description>Please enter hostname or IP of master machine where cluster to be setup</description>
          <defaultValue>10.88.67.158</defaultValue>
        </hudson.model.TextParameterDefinition>
        <hudson.model.TextParameterDefinition>
          <name>SLAVE_HOSTNAMES</name>
          <description>Please enter hostnames or IP for desired slaves in format slave_hostname1,slave_hostname2</description>
          <defaultValue>pts00450-vm22,pts00450-vm23</defaultValue>
        </hudson.model.TextParameterDefinition>
        <hudson.model.TextParameterDefinition>
          <name>HADOOP_VERSION</name>
          <description>Hadoop version you want for building cluster. Default is 2.7.1</description>
          <defaultValue>2.7.1</defaultValue>
        </hudson.model.TextParameterDefinition>
        <hudson.model.TextParameterDefinition>
          <name>FLAG_HIVE_MYSQL</name>
          <description>Flag to be set if you want mysql and hive setup with this hadoop and spark setup. Please select Y/N.
This is required to run spark benchmarks like Hibech and sparkbench</description>
          <defaultValue>Y</defaultValue>
        </hudson.model.TextParameterDefinition>
        <hudson.model.TextParameterDefinition>
          <name>SPARK_TEST</name>
          <description>Do you wish to run pi example for testing spark setup - Y/N</description>
          <defaultValue>Y</defaultValue>
        </hudson.model.TextParameterDefinition>
      </parameterDefinitions>
    </hudson.model.ParametersDefinitionProperty>
  </properties>
  <scm class="hudson.scm.NullSCM"/>
  <canRoam>true</canRoam>
  <disabled>false</disabled>
  <blockBuildWhenDownstreamBuilding>false</blockBuildWhenDownstreamBuilding>
  <blockBuildWhenUpstreamBuilding>false</blockBuildWhenUpstreamBuilding>
  <triggers/>
  <concurrentBuild>false</concurrentBuild>
  <builders>
    <hudson.tasks.Shell>
      <command>WORKDIR=$(ssh $USER@$MASTER_HOSTNAME &quot;pwd&quot;)

ssh $USER@$MASTER_HOSTNAME /bin/bash &lt;&lt;EOT
stop-all.sh 2&gt;&gt;/dev/null
echo &quot;Stoppped all running jobs&quot;
EOT

#ssh $USER@$MASTER_HOSTNAME &quot;rm spark-*-bin-hadoop-*.tgz&quot; &amp;&gt;&gt;/dev/null
cd
scp spark-*-bin-hadoop-*.tgz $USER@$MASTER_HOSTNAME:${WORKDIR}

ssh $USER@$MASTER_HOSTNAME /bin/bash &lt;&lt;EOT
echo &apos;Clonig repo Jenkins-hadoop-cluster-utils at location &apos;$WORKDIR&apos;&apos;
git clone https://github.com/nkalband/Jenkins-hadoop-cluster-utils.git -b branch-V1

echo &quot;Running autogen.sh&quot;
cd Jenkins-hadoop-cluster-utils
./autogen.sh $SLAVE_HOSTNAMES $HADOOP_VERSION $FLAG_HIVE_MYSQL
EOT

echo &quot;Running Setup.sh&quot;
ssh -t $USER@$MASTER_HOSTNAME /bin/bash &lt;&lt;EOT
cd Jenkins-hadoop-cluster-utils
./setup.sh $SPARK_TEST
EOT


</command>
    </hudson.tasks.Shell>
  </builders>
  <publishers>
    <hudson.tasks.BuildTrigger>
      <childProjects>Run_setup_tpcds</childProjects>
      <threshold>
        <name>SUCCESS</name>
        <ordinal>0</ordinal>
        <color>BLUE</color>
        <completeBuild>true</completeBuild>
      </threshold>
    </hudson.tasks.BuildTrigger>
  </publishers>
  <buildWrappers/>
</project>