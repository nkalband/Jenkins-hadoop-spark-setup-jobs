<?xml version='1.0' encoding='UTF-8'?>
<project>
  <actions/>
  <description></description>
  <keepDependencies>false</keepDependencies>
  <properties>
    <hudson.model.ParametersDefinitionProperty>
      <parameterDefinitions>
        <hudson.model.TextParameterDefinition>
          <name>BUILD_MACHINE</name>
          <description>Please enter hostname or IP of machine where Spark will be built and tested.</description>
          <defaultValue>10.88.67.158</defaultValue>
        </hudson.model.TextParameterDefinition>
        <hudson.model.TextParameterDefinition>
          <name>USER</name>
          <description>Enter the USER on the remote Build Machine under whom the build and testing will be done.</description>
          <defaultValue>hdp_test</defaultValue>
        </hudson.model.TextParameterDefinition>
        <hudson.model.TextParameterDefinition>
          <name>SPARK_BRANCH</name>
          <description>Enter the Spark branch to be cloned and built.</description>
          <defaultValue>2.0</defaultValue>
        </hudson.model.TextParameterDefinition>
        <hudson.model.TextParameterDefinition>
          <name>HADOOP_PROFILE</name>
          <description>Hadoop Profile you want for building cluster. Default is 2.7</description>
          <defaultValue>2.7</defaultValue>
        </hudson.model.TextParameterDefinition>
        <hudson.model.TextParameterDefinition>
          <name>BUILD_WITH_HIVE</name>
          <description>Flag to be set if you want hive setup with JDBC support with spark setup. Please select Y/N.</description>
          <defaultValue>Y</defaultValue>
        </hudson.model.TextParameterDefinition>
        <hudson.model.TextParameterDefinition>
          <name>JDK_VAL</name>
          <description>Set OPENJDK or IBMJDK for building and testing Spark.</description>
          <defaultValue>OPENJDK</defaultValue>
        </hudson.model.TextParameterDefinition>
        <hudson.model.TextParameterDefinition>
          <name>GIT_URLL</name>
          <description>Enter the Git Url which is used to clone spark</description>
          <defaultValue>https://github.com/apache/spark.git</defaultValue>
        </hudson.model.TextParameterDefinition>
      </parameterDefinitions>
    </hudson.model.ParametersDefinitionProperty>
    <org.jenkinsci.plugins.flow__plugin.FlowProjectProperty plugin="flow@1.3"/>
  </properties>
  <scm class="hudson.scm.NullSCM"/>
  <canRoam>true</canRoam>
  <disabled>false</disabled>
  <blockBuildWhenDownstreamBuilding>false</blockBuildWhenDownstreamBuilding>
  <blockBuildWhenUpstreamBuilding>false</blockBuildWhenUpstreamBuilding>
  <triggers/>
  <concurrentBuild>false</concurrentBuild>
  <builders>
    <hudson.tasks.Shell>
      <command>#!/bin/bash -e

echo &quot;------------------------------------------------&quot;
ssh ${USER}@${BUILD_MACHINE} /bin/bash &lt;&lt;EOF
echo &quot;These commands will be run on: $( uname -a )&quot;
echo &quot;They are executed by: $( whoami )&quot;

sudo kill -9 \$(sudo ps -ef | grep zin[c] | awk -F &quot; &quot; &apos;{print \$2}&apos;)

if [ -d spark ]
then 
	cd spark
    git pull
else
	git clone --recursive --depth 1 ${GIT_URLL} -b branch-${SPARK_BRANCH}
    cd spark
fi

echo &quot;------------------------------------------------&quot;

if [ ${JDK_VAL} = &quot;OPENJDK&quot; ]
then
  if [ &quot;$(. /etc/os-release; echo $NAME)&quot; = &quot;Ubuntu&quot; ]; then
        echo -en &quot;Setting OpenJDK path and JAVA_HOME\n&quot;
        export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-ppc64el
        export PATH=$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$PATH
      else
        echo -en &quot;Setting OpenJDK path and JAVA_HOME\n&quot;
        export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk
        export PATH=$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$PATH
      fi
elif [ ${JDK_VAL} = &quot;IBMJDK&quot; ]
then
  #export JAVA_HOME=$(grep -Po &apos;(?&lt;=USER_INSTALL_DIR=).*&apos; ${workDirR}/installer.properties)
  export PATH=$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$PATH
fi

java -version

echo &quot;------------------------------------------------&quot;

if [[ $BUILD_WITH_HIVE == &quot;y&quot; || $BUILD_WITH_HIVE == &quot;Y&quot; ]]
then
  echo &quot; Building with Hive and JDBC Support \n &quot;
  ./dev/make-distribution.sh --name hadoop-${HADOOP_PROFILE} --tgz -Psparkr -Phadoop-${HADOOP_PROFILE} -Phive -Phive-thriftserver -Pyarn
else 
  echo &quot; Building without Hive and JDBC Support \n &quot;
  ./dev/make-distribution.sh --name hadoop-${HADOOP_PROFILE} --tgz -Psparkr -Phadoop-${HADOOP_PROFILE} -Pyarn
fi
echo &quot;------------------------------------------------&quot;
EOF
</command>
    </hudson.tasks.Shell>
  </builders>
  <publishers/>
  <buildWrappers/>
</project>