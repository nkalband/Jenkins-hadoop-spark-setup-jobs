<?xml version='1.0' encoding='UTF-8'?>
<project>
  <actions/>
  <description></description>
  <keepDependencies>false</keepDependencies>
  <properties>
    <hudson.model.ParametersDefinitionProperty>
      <parameterDefinitions>
        <hudson.model.TextParameterDefinition>
          <name>BUILD_MACHINE</name>
          <description>Please enter hostname or IP of machine where Spark will be built and tested.</description>
          <defaultValue>9.3.126.18</defaultValue>
        </hudson.model.TextParameterDefinition>
        <hudson.model.TextParameterDefinition>
          <name>USER</name>
          <description>Enter the USER on the remote Build Machine under whom the build and testing will be done.</description>
          <defaultValue>testuser</defaultValue>
        </hudson.model.TextParameterDefinition>
        <hudson.model.PasswordParameterDefinition>
          <name>USER_PWD</name>
          <description>Enter the password for the USER of BUILD_MACHINE</description>
          <defaultValue>{AQAAABAAAACATP5fB5omxZiu2YtYHrOR3CTgprvotNWUsyl3GcnulyFQ74pzpqgZ/U+n+WCT1+4dAtf6O6i6mg8uWSkI+XdOajGC7uHjtILW9cPr3M5gC7VNqkUcvUCsZBKbnesbQHzU6z1XC7Q47ReZ5vZlePQAh94MhUFmhx2aLnr4+hLeaoSFind6Hwk8Uo2hkL/LJI0v}</defaultValue>
        </hudson.model.PasswordParameterDefinition>
        <hudson.model.TextParameterDefinition>
          <name>SPARK_BRANCH</name>
          <description>Enter the Spark branch to be cloned and built.</description>
          <defaultValue>2.0</defaultValue>
        </hudson.model.TextParameterDefinition>
        <hudson.model.TextParameterDefinition>
          <name>HADOOP_PROFILE</name>
          <description>Hadoop Profile you want for building cluster. Default is 2.7</description>
          <defaultValue>2.7</defaultValue>
        </hudson.model.TextParameterDefinition>
        <hudson.model.TextParameterDefinition>
          <name>BUILD_WITH_HIVE</name>
          <description>Flag to be set if you want hive setup with JDBC support with spark setup. Please select Y/N.</description>
          <defaultValue>Y</defaultValue>
        </hudson.model.TextParameterDefinition>
        <hudson.model.TextParameterDefinition>
          <name>JDK_VAL</name>
          <description>Set OPENJDK or IBMJDK for building and testing Spark.</description>
          <defaultValue>OPENJDK</defaultValue>
        </hudson.model.TextParameterDefinition>
        <hudson.model.TextParameterDefinition>
          <name>GIT_URLL</name>
          <description>Enter the Git Url which is used to clone spark</description>
          <defaultValue>https://github.com/apache/spark.git</defaultValue>
        </hudson.model.TextParameterDefinition>
      </parameterDefinitions>
    </hudson.model.ParametersDefinitionProperty>
  </properties>
  <scm class="hudson.scm.NullSCM"/>
  <canRoam>true</canRoam>
  <disabled>false</disabled>
  <blockBuildWhenDownstreamBuilding>false</blockBuildWhenDownstreamBuilding>
  <blockBuildWhenUpstreamBuilding>false</blockBuildWhenUpstreamBuilding>
  <triggers/>
  <concurrentBuild>false</concurrentBuild>
  <builders>
    <hudson.tasks.Shell>
      <command>#!/bin/bash -e

jenkins_ip=$(/sbin/ip -o -4 addr list eth0 | awk &apos;{print $4}&apos; | cut -d/ -f1)
jenkins_user=$( whoami )
ssh ${USER}@${BUILD_MACHINE} /bin/bash &lt;&lt;EOF
echo &quot;These commands will be run on: $( uname -a )&quot;
echo &quot;They are executed by: $( whoami )&quot;

rm -rf spark

sudo kill -9 \$(sudo ps -ef | grep zin[c] | awk -F &quot; &quot; &apos;{print \$2}&apos;)

git clone --recursive --depth 1 ${GIT_URLL} -b branch-${SPARK_BRANCH}

cd spark
COMMIT_HASH=\$(git log -n 1 --pretty=format:&quot;%H&quot;)

ssh ${jenkins_user}@${jenkins_ip} /bin/bash &lt;&lt;EOT
echo &apos;last_commit_hash=&apos;\${COMMIT_HASH}&apos;&apos; &gt; ~/build_dist_jenkins_var
EOT


if [ ${JDK_VAL} = &quot;OPENJDK&quot; ]
then
  if [ &quot;$(. /etc/os-release; echo $NAME)&quot; = &quot;Ubuntu&quot; ]; then
        echo -en &quot;Setting OpenJDK path and JAVA_HOME\n&quot;
        export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-ppc64el
        export PATH=$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$PATH
      else
        echo -en &quot;Setting OpenJDK path and JAVA_HOME\n&quot;
        export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk
        export PATH=$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$PATH
      fi
elif [ ${JDK_VAL} = &quot;IBMJDK&quot; ]
then
  #export JAVA_HOME=$(grep -Po &apos;(?&lt;=USER_INSTALL_DIR=).*&apos; ${workDirR}/installer.properties)
  export PATH=$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$PATH
fi

java -version

if [[ $BUILD_WITH_HIVE == &quot;y&quot; || $BUILD_WITH_HIVE == &quot;Y&quot; ]]
then
  echo &quot; Building with Hive and JDBC Support \n &quot;
  #build/mvn -Pyarn -Phadoop-${hadoopVer} -Psparkr -Dhadoop.version=${hadoopVer}.0 -Phive -Phive-thriftserver -DskipTests clean package
  ./dev/make-distribution.sh --name hadoop-${HADOOP_PROFILE} --tgz -Psparkr -Phadoop-${HADOOP_PROFILE} -Phive -Phive-thriftserver -Pyarn
else 
  echo &quot; Building without Hive and JDBC Support \n &quot;
  #build/mvn -Pyarn -Phadoop-${hadoopVer} -Psparkr -Dhadoop.version=${hadoopVer}.0 -DskipTests clean package
  ./dev/make-distribution.sh --name hadoop-${HADOOP_PROFILE} --tgz -Psparkr -Phadoop-${HADOOP_PROFILE} -Pyarn
fi
EOF


#Getting required variable in file to pass to downstream runbench job
echo &apos;git_url=&apos;${GIT_URLL}&apos;&apos; &gt;&gt; ~/build_dist_jenkins_var

exit 0</command>
    </hudson.tasks.Shell>
  </builders>
  <publishers>
    <hudson.tasks.BuildTrigger>
      <childProjects>Setup_spark</childProjects>
      <threshold>
        <name>SUCCESS</name>
        <ordinal>0</ordinal>
        <color>BLUE</color>
        <completeBuild>true</completeBuild>
      </threshold>
    </hudson.tasks.BuildTrigger>
  </publishers>
  <buildWrappers/>
</project>